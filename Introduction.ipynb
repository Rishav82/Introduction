{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Day 1: Introduction:"
      ],
      "metadata": {
        "id": "35WOurL8dELu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Data Collection and Cleaning\n",
        "\n",
        "1.Problem: You are given a dataset containing customer information for a retail company. The dataset includes missing values, outliers, and incorrect data entries. Clean the data by identifying and addressing the missing or erroneous values.\n",
        "\n",
        "2.Task:\n",
        "\n",
        "Load the dataset and identify any missing or incorrect data.\n",
        "\n",
        "Use techniques such as imputation, outlier removal, or data correction to clean the data.\n",
        "\n",
        "Document the methods you used for cleaning the data and explain why you chose them.\n",
        "\n"
      ],
      "metadata": {
        "id": "A1VMh8U1eemz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problem Statement\n",
        "\n",
        "Given a dataset containing customer information for a retail company.\n",
        "\n",
        "The dataset contains:\n",
        "\n",
        "Missing values\n",
        "\n",
        "Outliers\n",
        "\n",
        "Incorrect or inconsistent data entries\n",
        "\n",
        "Step 1: Load the Dataset & Identify Issues"
      ],
      "metadata": {
        "id": "scbjbBTPfoxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading dataset\n",
        "df = pd.read_csv(\"customer_data.csv\")\n",
        "\n",
        "# Displaying first few rows\n",
        "df.head()\n",
        "\n",
        "# Checking dataset structure\n",
        "df.info()\n",
        "\n",
        "# Checking missing values\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "lNCRu8jBfoIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Handling Missing Values\n",
        "\n",
        "Numerical Columns\n",
        "\n",
        "Using mean/median imputation\n",
        "\n",
        "Median is preferred when data contains outliers"
      ],
      "metadata": {
        "id": "l0ORbaX9iGYi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFRxHd_nc3Ry"
      },
      "outputs": [],
      "source": [
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "df['Annual_Income'] = df['Annual_Income'].fillna(df['Annual_Income'].median())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical Columns\n",
        "\n",
        "Use mode"
      ],
      "metadata": {
        "id": "ezs_7h7yiRRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gender'] = df['Gender'].fillna(df['Gender'].mode()[0])\n",
        "df['City'] = df['City'].fillna(df['City'].mode()[0])\n"
      ],
      "metadata": {
        "id": "b4c-kxaeieRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Detecting and Handling Outliers\n",
        "\n",
        "Using IQR Method"
      ],
      "metadata": {
        "id": "WKaLsrX1ijc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['Annual_Income'].quantile(0.25)\n",
        "Q3 = df['Annual_Income'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Removing outliers\n",
        "df = df[(df['Annual_Income'] >= lower_bound) & (df['Annual_Income'] <= upper_bound)]\n"
      ],
      "metadata": {
        "id": "OqgNhgS4inKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Correcting Incorrect Data Entries\n",
        "\n",
        "Removing negative age values\n",
        "\n",
        "Fixing inconsistent gender labels"
      ],
      "metadata": {
        "id": "-3imPGUPiwOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing invalid ages\n",
        "df = df[df['Age'] > 0]\n",
        "\n",
        "# Standardizing gender values\n",
        "df['Gender'] = df['Gender'].str.lower()\n",
        "df['Gender'] = df['Gender'].replace({'m': 'male', 'f': 'female'})\n"
      ],
      "metadata": {
        "id": "q-bzALLki74T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Verify Cleaned Data"
      ],
      "metadata": {
        "id": "87uzPorqjMiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "bESzEgxGjPhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Critical Thinking:\n",
        "\n",
        "Evaluate the impact of missing data on the results. How would different methods of dealing with missingdata affect the analysis?"
      ],
      "metadata": {
        "id": "QQc4A0JdjewE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Impact of Missing Data on Results\n",
        "\n",
        "Missing data can:\n",
        "\n",
        "Bias statistical measures\n",
        "\n",
        "Reduce model accuracy\n",
        "\n",
        "Lead to incorrect conclusions\n",
        "\n",
        "Different handling methods affect results differently:\n",
        "\n",
        "Deletion may reduce dataset size and lose information\n",
        "\n",
        "Mean/median imputation preserves size but may reduce variance\n",
        "\n",
        "Advanced imputation can improve accuracy but adds complexity"
      ],
      "metadata": {
        "id": "7QOoYlA-jriR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Higher-Order Thinking\n",
        "\n",
        "Suggest additional methods for improving data quality beyond what was discussed in the assignment."
      ],
      "metadata": {
        "id": "kTM11qCBj5SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Methods to Improve Data Quality\n",
        "1. Automated Validation Rules\n",
        "\n",
        "Range checks\n",
        "\n",
        "2. Advanced Imputation\n",
        "\n",
        "KNN Imputation\n",
        "\n",
        "Regression-based imputation\n",
        "\n",
        "3. Data Consistency Checks\n",
        "\n",
        "Cross-column validation\n",
        "\n",
        "4. Duplicate Detection\n",
        "\n",
        "Remove repeated customer records\n",
        "\n",
        "5. Data Versioning & Logging\n",
        "\n",
        "Track changes made during cleaning"
      ],
      "metadata": {
        "id": "2x29bng-kKz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 2: Data Visualization and Interpretation"
      ],
      "metadata": {
        "id": "a0m0YIiakrH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Create Visualizations\n",
        "\n",
        "Problem: Given a sales dataset, create at least three different types of visualizations that provide insights into sales trends, customer preferences, or regional performance.\n",
        "\n",
        "Task:\n",
        "> Use tools like Excel, Python (matplotlib or seaborn), or Tableau to create the visualizations.\n",
        "\n",
        "> Interpret the findings from each visualization. For example, how do trends change over time? Which regions have the highest sales?"
      ],
      "metadata": {
        "id": "YiYmWpr3k17J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problem Statement\n",
        "\n",
        "Given a sales dataset, create at least three different visualizations to provide insights into:\n",
        "Sales trends over time\n",
        "Customer preferences\n",
        "Regional performance\n",
        "\n",
        "Step 1: Loading Required Libraries and Dataset"
      ],
      "metadata": {
        "id": "ESgw9WjmlzYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Loading dataset\n",
        "sales_df = pd.read_csv(\"sales_data.csv\")\n",
        "\n",
        "# Previewing data\n",
        "sales_df.head()\n",
        "\n",
        "# Dataset overviewing\n",
        "sales_df.info()\n"
      ],
      "metadata": {
        "id": "K9fVSTZRl8T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumming Dataset Columns\n",
        "\n",
        "Date\n",
        "\n",
        "Region\n",
        "\n",
        "Product_Category\n",
        "\n",
        "Sales\n",
        "\n",
        "Customer_Type"
      ],
      "metadata": {
        "id": "AvCxCuxYmKhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting Date column to datetime\n",
        "sales_df['Date'] = pd.to_datetime(sales_df['Date'])\n"
      ],
      "metadata": {
        "id": "ycpwiQ1QmQlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Visualization 1: Line Chart – Sales Trend Over Time"
      ],
      "metadata": {
        "id": "gThF7qAYmUsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_over_time = sales_df.groupby('Date')['Sales'].sum()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(sales_over_time.index, sales_over_time.values)\n",
        "plt.title(\"Sales Trend Over Time\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Total Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3BrMa4thmXbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "The line graph shows how sales change over time.\n",
        "\n",
        "Upward trends indicate business growth.\n",
        "\n",
        "Sudden drops may indicate seasonal effects or operational issues."
      ],
      "metadata": {
        "id": "ZdqOWpV_mcas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization 2: Bar Chart – Sales by Region"
      ],
      "metadata": {
        "id": "3Wc93H7Mmj4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "region_sales = sales_df.groupby('Region')['Sales'].sum()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(region_sales.index, region_sales.values)\n",
        "plt.title(\"Total Sales by Region\")\n",
        "plt.xlabel(\"Region\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qCWZYgiSmmGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Regions with taller bars contribute more to overall revenue.\n",
        "\n",
        "Helps identify top-performing and underperforming regions.\n",
        "\n",
        "Useful for regional strategy planning."
      ],
      "metadata": {
        "id": "ASMXF6Fkmo0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization 3: Bar Chart – Customer Preferences"
      ],
      "metadata": {
        "id": "hC0Vt0f0mtas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_sales = sales_df.groupby('Product_Category')['Sales'].sum()\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(x=category_sales.index, y=category_sales.values)\n",
        "plt.title(\"Sales by Product Category\")\n",
        "plt.xlabel(\"Product Category\")\n",
        "plt.ylabel(\"Sales\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TSzUczd5mzrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Highlights which product categories are most popular.\n",
        "\n",
        "Helps inventory and marketing teams focus on high-demand products."
      ],
      "metadata": {
        "id": "dEbKzHJim22A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Critical Thinking:\n",
        "> What visualization would best convey trends in sales over time? Why?\n",
        "> How could you improve these visualizations for a non-technical audience?"
      ],
      "metadata": {
        "id": "LYLdYA9fnBTW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Best Visualization for Sales Trends Over Time\n",
        "\n",
        "Answer:\n",
        "\n",
        "A line chart is the best visualization for sales trends over time because:\n",
        "\n",
        "It clearly shows increases and decreases\n",
        "\n",
        "Trends and seasonality are easy to observe\n",
        "\n",
        "Time-based comparisons are intuitive\n",
        "\n",
        "2. Improving Visualizations for a Non-Technical Audience\n",
        "\n",
        "Use simple titles and labels\n",
        "\n",
        "Add annotations\n",
        "\n",
        "Use consistent colors\n",
        "\n",
        "Avoid excessive data points\n",
        "\n",
        "Use summary charts instead of raw scatter plots"
      ],
      "metadata": {
        "id": "eGb3BKy9njUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Higher-Order Thinking:\n",
        "> Compare and contrast two visualizations of the same data. Which one provides clearer insights and why?"
      ],
      "metadata": {
        "id": "9_pr15ldn24I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare Two Visualizations of the Same Data\n",
        "\n",
        "Line Chart vs Scatter Plot\n",
        "\n",
        "| Aspect           | Line Chart       | Scatter Plot      |\n",
        "| ---------------- | ---------------- | ----------------- |\n",
        "| Trend visibility | Very clear       | Less clear        |\n",
        "| Noise handling   | Smooth           | Noisy             |\n",
        "| Best use case    | Long-term trends | Outlier detection |\n"
      ],
      "metadata": {
        "id": "-0nMbFnRoG9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 3: Introduction to Predictive Analytics"
      ],
      "metadata": {
        "id": "lFR8lGsLoUrm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Build a Predictive Mode\n",
        "1. Problem: Use a dataset of past customer purchases to build a predictive model that forecasts whether a new customer will make a purchase in the future.\n",
        "\n",
        "2. Task:\n",
        "\n",
        "Split the dataset into training and test sets.\n",
        "Choose a simple algorithm (e.g., logistic regression or decision tree) and build the model.\n",
        "\n",
        "Evaluate the model using appropriate metrics (e.g., accuracy, precision)."
      ],
      "metadata": {
        "id": "SVkxvX1LoeOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problem Statement\n",
        "\n",
        "Using past customer purchase data, build a model that predicts whether a new customer will make a purchase in the future.\n",
        "\n",
        "Target Variable:\n",
        "\n",
        "Purchased → 1 (Yes), 0 (No)\n",
        "\n",
        "Step 1: Importing Libraries & Load Dataset"
      ],
      "metadata": {
        "id": "5auiSG4JpQTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Loading dataset\n",
        "df = pd.read_csv(\"customer_purchase_data.csv\")\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "IsPa04S_pYWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumed Dataset Columns\n",
        "\n",
        "Age\n",
        "\n",
        "Annual_Income\n",
        "\n",
        "Spending_Score\n",
        "\n",
        "Purchased\n",
        "\n",
        "Step 2: Featuring Selection & Data Preparation"
      ],
      "metadata": {
        "id": "LUmwn5pQphuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Age', 'Annual_Income', 'Spending_Score']]\n",
        "y = df['Purchased']\n"
      ],
      "metadata": {
        "id": "BK7Tgk4bppRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train–Test Spliting"
      ],
      "metadata": {
        "id": "iHGiyu5hptQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "CkLPH4iCpwuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Feature Scaling"
      ],
      "metadata": {
        "id": "gM-qi6rqpzsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "EjeTTiJDp1pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Build the Predictive Model"
      ],
      "metadata": {
        "id": "qsoOPqj-p4sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n"
      ],
      "metadata": {
        "id": "4d6mtNUBp7a-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Making Predictions"
      ],
      "metadata": {
        "id": "_QYroWQup-AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "INkUb1yAqQGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Model Evaluation"
      ],
      "metadata": {
        "id": "K25PCRPcqbRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "accuracy, precision, recall, f1\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "x9x2X0PmqeM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of Results\n",
        "\n",
        "Accuracy: Overall model correctness\n",
        "\n",
        "Precision: How many predicted buyers actually purchased\n",
        "\n",
        "Recall: How many actual buyers were correctly identified\n",
        "\n",
        "F1 Score: Balanced performance metric\n",
        "\n",
        "✔ Logistic Regression works well for binary classification and is easy to interpret."
      ],
      "metadata": {
        "id": "_gf2vFyvqoG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Critical Thinking:\n",
        "How would you handle an imbalanced dataset (e.g., more customers who do not make a purchase than those who do)?\n",
        "How can you improve the predictive power of your model?"
      ],
      "metadata": {
        "id": "t4Tg7Je3qweV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Handling Imbalanced Datasets\n",
        "\n",
        "If most customers do not purchase, the dataset becomes imbalanced.\n",
        "\n",
        "Solutions\n",
        "\n",
        "Resampling\n",
        "\n",
        "Oversample minority class\n",
        "\n",
        "Undersample majority class\n",
        "\n",
        "Class Weights\n",
        "\n",
        "Penalize wrong predictions of minority class\n",
        "\n",
        "Use better metrics\n",
        "\n",
        "Precision, Recall, F1 instead of Accuracy\n",
        "\n",
        "2. Improving Predictive Power\n",
        "\n",
        "Add more relevant features\n",
        "\n",
        "Feature engineering\n",
        "\n",
        "Try advanced models:\n",
        "\n",
        "Decision Tree\n",
        "\n",
        "Random Forest\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "Hyperparameter tuning\n",
        "\n",
        "Increase dataset size"
      ],
      "metadata": {
        "id": "o1PBIKlDq-xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Higher-Order Thinking:\n",
        "Discuss the potential ethical implications of predictive models in business decisions. How could bias impact these models?"
      ],
      "metadata": {
        "id": "DIiSEQ7hr07_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ethical Implications of Predictive Models\n",
        "\n",
        "Predictive models can strongly influence business decisions such as:\n",
        "\n",
        "Who receives discounts\n",
        "\n",
        "Who gets targeted ads\n",
        "\n",
        "Who is denied offers\n",
        "\n",
        "Potential Ethical Risks\n",
        "\n",
        "Bias in data\n",
        "\n",
        "Historical bias can disadvantage certain groups\n",
        "\n",
        "Unfair targeting\n",
        "\n",
        "Excluding customers based on predictions\n",
        "\n",
        "Privacy concerns\n",
        "\n",
        "Misuse of personal data\n",
        "\n",
        "Mitigation Strategies\n",
        "\n",
        "Regular bias audits\n",
        "\n",
        "Transparent models\n",
        "\n",
        "Ethical data collection\n",
        "\n",
        "Human oversight in decision-making"
      ],
      "metadata": {
        "id": "uqjsw8Yzr86X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 4: Advanced Data Analytics Techniques"
      ],
      "metadata": {
        "id": "PQHIN3YJsSRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Customer Segmentation Using Clustering\n",
        "1. Problem:\n",
        "\n",
        "You have a dataset of customer behavior (e.g., purchase history, browsing behavior). Use clustering techniques to group customers into segments that share similar characteristics.\n",
        "\n",
        "2. Task:\n",
        "\n",
        "Apply a clustering algorithm (e.g., K-means) on the dataset\n",
        "Identify meaningful customer segments and interpret their characteristics (e.g., high-value customers, frequent shoppers)"
      ],
      "metadata": {
        "id": "0gqGz3pksY42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Problem Statement\n",
        "\n",
        "You are given a dataset containing customer behavior such as:\n",
        "\n",
        "Purchase history\n",
        "\n",
        "Browsing behavior\n",
        "\n",
        "Spending patterns\n",
        "\n",
        "Your task is to group customers into meaningful segments using clustering.\n",
        "\n",
        "Step 1: Import Libraries & Load Dataset"
      ],
      "metadata": {
        "id": "WAVq82e4tArf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Loading dataset\n",
        "df = pd.read_csv(\"customer_behavior_data.csv\")\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "8Ts4Jb_ItKCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumming Dataset Columns\n",
        "\n",
        "Annual_Income\n",
        "\n",
        "Spending_Score\n",
        "\n",
        "Purchase_Frequency\n",
        "\n",
        "Step 2: Feature Selection"
      ],
      "metadata": {
        "id": "EVhovMqxtRCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Annual_Income', 'Spending_Score', 'Purchase_Frequency']]\n"
      ],
      "metadata": {
        "id": "T_18E3EHta9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Feature Scaling\n",
        "\n",
        "Clustering algorithms are distance-based, so scaling is essential."
      ],
      "metadata": {
        "id": "T55QliFutd5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "B0pgz3oEtiaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Choosing the Optimal Number of Clusters"
      ],
      "metadata": {
        "id": "81RZLxTltlUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wcss = []\n",
        "\n",
        "for k in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(range(1, 11), wcss, marker='o')\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZUQAkpNZtn-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "The “elbow point” represents a balance between performance and simplicity\n",
        "Assume K = 4 based on the elbow curve\n",
        "\n",
        "Step 5: Apply K-Means Clustering"
      ],
      "metadata": {
        "id": "euiWFPF_tuFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "AY1Y7o5Vtyoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Visualize Customer Segments"
      ],
      "metadata": {
        "id": "G9f8fQ_pt2y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(df['Annual_Income'], df['Spending_Score'], c=df['Cluster'])\n",
        "plt.title(\"Customer Segments\")\n",
        "plt.xlabel(\"Annual Income\")\n",
        "plt.ylabel(\"Spending Score\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pwwNn9_wt4mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Interpreting Customer Segments"
      ],
      "metadata": {
        "id": "qkxRj5Lwt82W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('Cluster').mean()\n"
      ],
      "metadata": {
        "id": "iSbIJ2_Dt__x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster Interpretation\n",
        "\n",
        "| Cluster | Characteristics                  | Customer Type        |\n",
        "| ------- | -------------------------------- | -------------------- |\n",
        "| 0       | High income, high spending       | High-value customers |\n",
        "| 1       | Low income, low spending         | Low-value customers  |\n",
        "| 2       | High income, low spending        | Potential customers  |\n",
        "| 3       | Moderate income, frequent buyers | Loyal customers      |\n"
      ],
      "metadata": {
        "id": "25fFPdrbuD6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Critical Thinking:\n",
        "What business strategies could be implemented for different customer segments?\n",
        "What challenges did you face when choosing the right number of clusters?"
      ],
      "metadata": {
        "id": "sDZb4BRIuNjB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Business Strategies for Different Segments\n",
        "\n",
        "High-value customers\n",
        "\n",
        "Loyalty programs\n",
        "\n",
        "Premium offers\n",
        "\n",
        "Frequent shoppers\n",
        "\n",
        "Subscription plans\n",
        "\n",
        "Personalized discounts\n",
        "\n",
        "Low-engagement customers\n",
        "\n",
        "Targeted promotions\n",
        "\n",
        "Re-engagement campaigns\n",
        "\n",
        "Potential customers\n",
        "\n",
        "Personalized recommendations\n",
        "\n",
        "Incentives to increase spending\n",
        "\n",
        "2. Challenges in Choosing the Right Number of Clusters\n",
        "\n",
        "Elbow point not always clear\n",
        "\n",
        "Too many clusters → overfitting\n",
        "\n",
        "Too few clusters → oversimplification\n",
        "\n",
        "Business interpretability vs mathematical optimality\n",
        "\n",
        "✔ Cluster choice should balance analytics + business understanding"
      ],
      "metadata": {
        "id": "VIJlPFjYvgbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Higher-Order Thinking:\n",
        "How would you use clustering to improve customer retention strategies in a business?\n"
      ],
      "metadata": {
        "id": "RD5L57h9vzck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Clustering to Improve Customer Retention\n",
        "\n",
        "Clustering can significantly enhance customer retention by:\n",
        "\n",
        "Identifying customers at risk of churn\n",
        "\n",
        "Creating personalized retention strategies\n",
        "\n",
        "Detecting declining engagement early\n",
        "\n",
        "Tailoring communication and offers"
      ],
      "metadata": {
        "id": "lhwbCaauwAlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 5: Decision Making and Optimization"
      ],
      "metadata": {
        "id": "TJpSUjWQwHmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Optimization of Marketing Campaign\n",
        "\n",
        "Problem: You are working as a data analyst for a company launching a new marketing campaign. Use data analytics to identify the best strategy to maximize return on investment (ROI)\n",
        "\n",
        "2. Task:\n",
        "\n",
        "Analyze customer demographics, previous campaign performance, and engagement metrics.\n",
        "\n",
        "Recommend an optimal marketing strategy that targets the most relevant customer segments.\n",
        "\n",
        "Explain how data supports your decision-making process."
      ],
      "metadata": {
        "id": "NbjSz1vOwMVa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "\n",
        "You are working as a data analyst for a company launching a new marketing campaign.Your goal is to use data analytics to identify the best strategy to maximize ROI.\n",
        "\n",
        "Step 1: Loading Libraries & Dataset"
      ],
      "metadata": {
        "id": "u_oUF_hSw9S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load marketing dataset\n",
        "df = pd.read_csv(\"marketing_campaign_data.csv\")\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "1e6mmFOSxD7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assumming Dataset Columns\n",
        "\n",
        "Customer_Age\n",
        "\n",
        "Income\n",
        "\n",
        "Customer_Segment\n",
        "\n",
        "Marketing_Channel\n",
        "\n",
        "Campaign_Cost\n",
        "\n",
        "Revenue_Generated\n",
        "\n",
        "Engagement_Score\n",
        "\n",
        "Step 2: Calculating ROI\n",
        "\t​\n"
      ],
      "metadata": {
        "id": "bnpg_Zd9xJfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['ROI'] = (df['Revenue_Generated'] - df['Campaign_Cost']) / df['Campaign_Cost']\n",
        "\n",
        "df[['Marketing_Channel', 'Campaign_Cost', 'Revenue_Generated', 'ROI']].head()\n"
      ],
      "metadata": {
        "id": "6SgdEKPjxWy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Analyzing Performance by Marketing Channel"
      ],
      "metadata": {
        "id": "gx1vRx5SxcI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "channel_performance = df.groupby('Marketing_Channel')[['Campaign_Cost', 'Revenue_Generated', 'ROI']].mean()\n",
        "channel_performance\n"
      ],
      "metadata": {
        "id": "JIgMPRhkxenp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Higher ROI → better return for money spent\n",
        "\n",
        "Channels with high revenue but low ROI may be inefficient\n",
        "\n",
        "Step 4: Customer Segment Analysis"
      ],
      "metadata": {
        "id": "kxS2Oq_exiLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "segment_performance = df.groupby('Customer_Segment')['ROI'].mean().sort_values(ascending=False)\n",
        "segment_performance\n"
      ],
      "metadata": {
        "id": "vhl6C6gMxll8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights\n",
        "\n",
        "Certain customer segments consistently generate higher ROI\n",
        "\n",
        "Marketing efforts should focus on high-ROI segments\n",
        "\n",
        "Step 5: Engagement-Based Optimization"
      ],
      "metadata": {
        "id": "cIeL3OiHxpeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "engagement_roi = df.groupby('Marketing_Channel')['Engagement_Score'].mean()\n",
        "engagement_roi\n"
      ],
      "metadata": {
        "id": "l4lXQY6TxtMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight\n",
        "\n",
        "Channels with high engagement often correlate with higher ROI\n",
        "\n",
        "Engagement metrics help validate marketing effectiveness\n",
        "\n",
        "How Data Supports Decision-Making\n",
        "\n",
        "ROI identifies profitable strategies\n",
        "\n",
        "Segmentation reveals where marketing works best\n",
        "\n",
        "Engagement metrics validate customer interest\n",
        "\n",
        "Historical performance reduces guesswork"
      ],
      "metadata": {
        "id": "pQlSZ32Sxv0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. Critical Thinking:\n",
        "What factors could lead to an ineffective marketing strategy even if the data suggests it's the best option?\n",
        "How would you handle uncertain or incomplete data when making recommendations?"
      ],
      "metadata": {
        "id": "RDAn2tmfx79y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Why a Data-Suggested Strategy Might Still Fail\n",
        "\n",
        "Market conditions change\n",
        "\n",
        "Customer preferences evolve\n",
        "\n",
        "Data may be outdated\n",
        "\n",
        "External factors\n",
        "\n",
        "Poor campaign execution despite good strategy\n",
        "\n",
        "2. Handling Uncertain or Incomplete Data\n",
        "\n",
        "Use assumptions with confidence intervals\n",
        "\n",
        "Rely on multiple metrics, not one\n",
        "\n",
        "Run pilot campaigns or A/B tests\n",
        "\n",
        "Continuously update models as new data arrives"
      ],
      "metadata": {
        "id": "0ovLchoxyLiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Higher-Order Thinking:\n",
        "Propose a data-driven approach to optimize the allocation of marketing resources across different channels (e.g., social media, email marketing, direct mail)."
      ],
      "metadata": {
        "id": "1atnMsEayUzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizing Marketing Resource Allocation Across Channels\n",
        "\n",
        "Proposed Data-Driven Approach\n",
        "\n",
        "Budget Allocation by ROI\n",
        "\n",
        "Assign higher budget to channels with higher ROI\n",
        "\n",
        "Multi-Channel Optimization\n",
        "\n",
        "Combine channels for different customer segments\n",
        "\n",
        "A/B Testing\n",
        "\n",
        "Test variations in messaging and channel mix\n",
        "\n",
        "Continuous Feedback Loop\n",
        "\n",
        "Monitor performance in real time\n",
        "\n",
        "Reallocate budget dynamically"
      ],
      "metadata": {
        "id": "3ldQ4y_7yecf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7jJrST-2tCC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}